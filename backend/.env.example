# LLM Provider: "ollama" (local) or "openai"
LLM_PROVIDER=ollama

# Ollama settings (default)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# OpenAI settings (only needed if LLM_PROVIDER=openai)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini

# Embedding model (runs locally, downloaded once)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# ChromaDB local persistence path
CHROMA_DB_PATH=./data/chromadb

# BM25 index pickle path
BM25_INDEX_PATH=./data/bm25_index.pkl

# CORS origin for frontend
FRONTEND_ORIGIN=http://localhost:5173

# CRAG relevance threshold (0.0 - 1.0)
CRAG_RELEVANCE_THRESHOLD=0.30

# RRF fusion parameter
RRF_K=60

# Chunking settings
CHUNK_SIZE=512
CHUNK_OVERLAP=64
