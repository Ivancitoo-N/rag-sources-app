# RAG Sources App üß†

Una aplicaci√≥n web de RAG (Retrieval-Augmented Generation) totalmente **local** para consultar fuentes de documentos exclusivas con b√∫squeda h√≠brida, generaci√≥n basada en hechos (CRAG) y citaciones directas.

![Aesthetic Visualization](https://img.shields.io/badge/Design-Glassmorphism-blueviolet)
![Tech](https://img.shields.io/badge/Stack-FastAPI%20%2B%20React-blue)
![Privacy](https://img.shields.io/badge/Privacy-100%25%20Local-green)

## ‚ú® Caracter√≠sticas Principales

- **üîç B√∫squeda H√≠brida**: Combina b√∫squeda sem√°ntica (ChromaDB + Sentence-Transformers) con b√∫squeda l√©xica (BM25) mediante **Reciprocal Rank Fusion (RRF)**.
- **üõ° CRAG (Corrective RAG)**: Eval√∫a la relevancia de los fragmentos recuperados antes de generar la respuesta para evitar alucinaciones.
- **üìÑ Extracci√≥n de Alta Precisi√≥n**: Utiliza **Docling** para procesar PDFs, DOCX y Markdown con una precisi√≥n excelente en tablas y estructuras complejas.
- **üìÅ Colecciones (Multi-Chat)**: Organiza tus documentos en grupos aislados. Las consultas en una colecci√≥n no tienen acceso a los datos de otra.
- **üìç Citaciones Directas**: Cada respuesta del IA incluye referencias precisas al documento y p√°gina de origen.
- **üé® Interfaz Premium**: Dise√±o moderno con Glassmorphism, temas oscuros y animaciones fluidas.

## üõ† Requisitos Previos

- **Python 3.10+**
- **Node.js 18+**
- **Ollama** (opcional, para ejecuci√≥n local de LLM) o clave de **OpenAI API**.

## üöÄ Instalaci√≥n R√°pida (Windows)

1. **Clonar el repositorio** (o descargar los archivos).
2. **Configurar el entorno**:
   ```bash
   cp backend/.env.example backend/.env
   ```
   Edita `backend/.env` para configurar tu proveedor de LLM (`ollama` o `openai`).
3. **Lanzar la aplicaci√≥n**:
   Simplemente ejecuta el archivo:
   ```cmd
   start.bat
   ```
   *Este script instalar√° autom√°ticamente las dependencias, configurar√° el entorno virtual y lanzar√° tanto el backend como el frontend en terminales separadas.*

## üìÇ Estructura del Proyecto

- `backend/`: API FastAPI, l√≥gica de ingesta, stores de vectores (ChromaDB) y b√∫squeda h√≠brida.
- `frontend/`: Interfaz React + Vite + TypeScript con soporte para Drag & Drop.
- `data/`: Almacenamiento local persistente para ChromaDB y el √≠ndice BM25.

## ‚öôÔ∏è Configuraci√≥n (.env)

| Variable | Descripci√≥n | Valor por defecto |
|----------|-------------|-------------------|
| `LLM_PROVIDER` | Proveedor de LLM | `ollama` |
| `OLLAMA_MODEL` | Modelo de Ollama | `llama3.2` |
| `OPENAI_API_KEY` | Key de OpenAI | `sk-...` |
| `CRAG_RELEVANCE_THRESHOLD` | Umbral de relevancia | `0.20` |

## üõ° Seguridad y Privacidad

Esta aplicaci√≥n est√° dise√±ada para ser **local-first**. Tus documentos nunca salen de tu m√°quina durante el proceso de ingesta o b√∫squeda l√©xica/vectorial. Si usas Ollama, el 100% de la l√≥gica (incluyendo la generaci√≥n) es privada.

---
*Desarrollado con enfoque en precisi√≥n industrial y experiencia de usuario premium.*
